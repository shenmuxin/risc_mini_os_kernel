## 6. 锁

[toc]

大多数内核，包括xv6，交错执行多个活动。交错的一个来源是多处理器硬件：计算机的多个CPU之间独立执行，如xv6的RISC-V。多个处理器共享物理内存，xv6利用共享（sharing）来维护所有CPU进行读写的数据结构。这种共享增加了一种可能性，即一个CPU读取数据结构，而另一个CPU正在更新它，甚至多个CPU同时更新相同的数据；如果不仔细设计，这种并行访问可能会产生不正确的结果或损坏数据结构。即使在单处理器上，内核也可能在许多线程之间切换CPU，导致它们的执行交错。最后，如果中断发生在错误的时间，设备中断处理程序修改与某些可中断代码相同的数据，可能导致数据损坏。单词并发（concurrency）是指由于多处理器并行、线程切换或中断，多个指令流交错的情况。

内核中充满了并发访问数据（concurrently-accessed data）。例如，两个CPU可以同时调用`kalloc`，从而从空闲列表的头部弹出。内核设计者希望允许大量的并发，因为这样可通过并行性提高性能，并提高响应能力。然而，结果是，尽管存在这种并发性，内核设计者还是花费了大量的精力来使其正确运行。有许多方法可以得到正确的代码，有些方法比其他方法更容易。以并发下的正确性为目标的策略和支持它们的抽象称为并发控制技术（concurrency control techniques）。

Xv6使用了许多并发控制技术，这取决于不同的情况。本章重点介绍了一种广泛使用的技术：**锁**。锁提供了互斥，确保一次只有一个CPU可以持有锁。如果程序员将每个共享数据项关联一个锁，并且代码在使用一个数据项时总是持有相关联的锁，那么该项一次将只被一个CPU使用。在这种情况下，我们说锁保护数据项。尽管锁是一种易于理解的并发控制机制，但锁的缺点是它们会扼杀性能，因为它们会串行化并发操作。

本章的其余部分解释了为什么xv6需要锁，xv6如何实现它们，以及如何使用它们。



### 6.1 竞态条件

作为我们为什么需要锁的一个例子，考虑两个进程在两个不同的CPU上调用`wait`。`wait`释放了子进程的内存。因此，在每个CPU上，内核将调用`kfree`来释放子进程的页面。内核分配器维护一个链接列表：`kalloc()`(***kernel/kalloc.c:69***) 从空闲页面列表中取出（pop）一个内存页面；`kfree()`(***kernel/kalloc.c:47***) 将一个内存页面添加（push）到空闲列表上。为了获得最佳性能，我们可能希望两个父进程的`kfree`可以并行执行，而不必等待另一个进程，但是考虑到xv6的`kfree`实现，这将导致错误。

 ![6_1png](/home/sjh/Documents/Markdown_Note/MIT6.S801.assets/6_1png) 

图6.1更详细地说明了这项设定：链表位于两个CPU共享的内存中，这两个CPU使用`load`和`store`指令操作链表。（实际上，每个处理器都有cache，但从概念上讲，多处理器系统的行为就像所有CPU共享一块单独的内存一样）如果没有并发请求，您可能以如下方式实现列表push操作：

```c
struct element {
    int data;
    struct element *next;
}; 

struct element *list = 0;

void 
push(int data)
{
    struct element *l;

    l = malloc(sizeof *l);
    l->data = data;
    l->next = list;
    list = l; 
}
```

![6_2](/home/sjh/Documents/Markdown_Note/MIT6.S801.assets/6_2.png)

如果存在隔离性，那么这个实现是正确的。但是，如果多个副本并发执行，代码就会出错。如果两个CPU同时执行`push`，如图6.1所示，两个CPU都可能在执行第16行之前执行第15行，这会导致如图6.2所示的不正确的结果。然后会有两个类型为`element`的列表元素使用`next`指针设置为`list`的前一个值。当两次执行位于第16行的对`list`的赋值时，第二次赋值将覆盖第一次赋值；第一次赋值中涉及的元素将丢失。

第16行丢失的更新是竞态条件（race condition）的一个例子。竞态条件是指多个进程读写某些共享数据（至少有一个访问是写入）的情况。竞争通常包含bug，要么丢失更新（如果访问是写入的），要么读取未完成更新的数据结构。竞争的结果取决于进程在处理器运行的确切时机以及内存系统如何排序它们的内存操作，这可能会使竞争引起的错误难以复现和调试。例如，在调试`push`时添加`printf`语句可能会改变执行的时间，从而使竞争消失。

避免竞争的通常方法是使用锁。锁确保互斥，这样一次只有一个CPU可以执行`push`中敏感的代码行；这使得上述情况不可能发生。上面代码的正确上锁版本只添加了几行（用黄色突出显示）：

```c
struct element {
    int data;
    struct element *next;
}; 

struct element *list = 0;
struct lock listlock;		// hight light

void 
push(int data)
{
    struct element *l;

    l = malloc(sizeof *l);
    l->data = data;
    acquire(&listlock);		// hight light
    l->next = list;
    list = l; 
    release(&listlock);		// hight light
}
```

`acquire`和`release`之间的指令序列通常被称为临界区域（critical section）。锁的作用通常被称为保护`list`。

当我们说锁保护数据时，我们实际上是指锁保护适用于数据的某些不变量集合。不变量是跨操作维护的数据结构的属性。通常，操作的正确行为取决于操作开始时不变量是否为真。操作可能暂时违反不变量，但必须在完成之前重新建立它们。例如，在链表的例子中，不变量是`list`指向列表中的第一个元素，以及每个元素的`next`字段指向下一个元素。`push`的实现暂时违反了这个不变量：在第17行，`l->next`指向`list`（注：则此时`list`不再指向列表中的第一个元素，即违反了不变量），但是`list`还没有指向`l`（在第18行重新建立）。我们上面检查的竞态条件发生了，因为第二个CPU执行了依赖于列表不变量的代码，而这些代码（暂时）被违反了。正确使用锁可以确保每次只有一个CPU可以对临界区域中的数据结构进行操作，因此当数据结构的不变量不成立时，将没有其他CPU对数据结构执行操作。

您可以将锁视为串行化（serializing）并发的临界区域，以便同时只有一个进程在运行这部分代码，从而维护不变量（假设临界区域设定了正确的隔离性）。您还可以将由同一锁保护的临界区域视为彼此之间的原子，即彼此之间只能看到之前临界区域的完整更改集，而永远看不到部分完成的更新。

尽管正确使用锁可以改正不正确的代码，但锁限制了性能。例如，如果两个进程并发调用`kfree`，锁将串行化这两个调用，我们在不同的CPU上运行它们没有任何好处。如果多个进程同时想要相同的锁或者锁经历了争用，则称之为发生冲突（conflict）。内核设计中的一个主要挑战是避免锁争用。Xv6为此几乎没做任何工作，但是复杂的内核会精心设计数据结构和算法来避免锁的争用。在链表示例中，内核可能会为每个CPU维护一个空闲列表，并且只有当CPU的列表为空并且必须从另一个CPU挪用内存时才会触及另一个CPU的空闲列表。其他用例可能需要更复杂的设计。

锁的位置对性能也很重要。例如，在`push`中把`acquire`的位置提前也是正确的：将`acquire`移动到第13行之前完全没问题。但这样对`malloc`的调用也会被串行化，从而降低了性能。下面的《使用锁》一节提供了一些关于在哪里插入`acquire`和`release`调用的指导方针。

### 6.2 代码: Locks

Xv6有两种类型的锁：自旋锁（spinlocks）和睡眠锁（sleep-locks）。我们将从自旋锁（注：自旋，即循环等待）开始。Xv6将自旋锁表示为`struct spinlock` (***kernel/spinlock.h:2***)。结构体中的重要字段是`locked`，当锁可用时为零，当它被持有时为非零。从逻辑上讲，xv6应该通过执行以下代码来获取锁。

```bash
void
acquire(struct spinlock* lk) // does not work!
{
  for(;;) {
    if(lk->locked == 0) {
      lk->locked = 1;
      break;
    }
  }
}
```

不幸的是，这种实现不能保证多处理器上的互斥。可能会发生两个CPU同时到达第5行，看到`lk->locked`为零，然后都通过执行第6行占有锁。此时就有两个不同的CPU持有锁，从而违反了互斥属性。我们需要的是一种方法，使第5行和第6行作为原子（即不可分割）步骤执行。

因为锁被广泛使用，多核处理器通常提供实现第5行和第6行的原子版本的指令。在RISC-V上，这条指令是`amoswap r, a`。`amoswap`读取内存地址`a`处的值，将寄存器`r`的内容写入该地址，并将其读取的值放入`r`中。也就是说，它交换寄存器和指定内存地址的内容。它原子地执行这个指令序列，使用特殊的硬件来防止任何其他CPU在读取和写入之间使用内存地址。

Xv6的`acquire`(***kernel/spinlock.c:22***)使用可移植的C库调用归结为`amoswap`的指令`__sync_lock_test_and_set`；返回值是`lk->locked`的旧（交换了的）内容。`acquire`函数将swap包装在一个循环中，直到它获得了锁前一直重试（自旋）。每次迭代将1与`lk->locked`进行swap操作，并检查`lk->locked`之前的值。如果之前为0，swap已经把`lk->locked`设置为1，那么我们就获得了锁；如果前一个值是1，那么另一个CPU持有锁，我们原子地将1与`lk->locked`进行swap的事实并没有改变它的值。

获取锁后，用于调试，`acquire`将记录下来获取锁的CPU。`lk->cpu`字段受锁保护，只能在保持锁时更改。

函数`release`(***kernel/spinlock.c:47***) 与`acquire`相反：它清除`lk->cpu`字段，然后释放锁。从概念上讲，`release`只需要将0分配给`lk->locked`。C标准允许编译器用多个存储指令实现赋值，因此对于并发代码，C赋值可能是非原子的。因此`release`使用执行原子赋值的C库函数`__sync_lock_release`。该函数也可以归结为RISC-V的`amoswap`指令。

### 6.3 代码: 使用锁

Xv6在许多地方使用锁来避免竞争条件（race conditions）。如上所述，`kalloc`(***kernel/kalloc.c:69***)和`kfree`(***kernel/kalloc.c:47***)就是一个很好的例子。尝试练习1和练习2，看看如果这些函数省略了锁会发生什么。你可能会发现很难触发不正确的行为，这表明很难可靠地测试代码是否经历了锁错误和竞争后被释放。xv6有一些竞争是有可能发生的。

使用锁的一个困难部分是决定要使用多少锁，以及每个锁应该保护哪些数据和不变量。有几个基本原则。首先，任何时候可以被一个CPU写入，同时又可以被另一个CPU读写的变量，都应该使用锁来防止两个操作重叠。其次，请记住锁保护不变量（invariants）：如果一个不变量涉及多个内存位置，通常所有这些位置都需要由一个锁来保护，以确保不变量不被改变。

上面的规则说什么时候需要锁，但没有说什么时候不需要锁。为了提高效率，不要向太多地方上锁是很重要的，因为锁会降低并行性。如果并行性不重要，那么可以安排只拥有一个线程，而不用担心锁。一个简单的内核可以在多处理器上做到这一点，方法是拥有一个锁，这个锁必须在进入内核时获得，并在退出内核时释放（尽管如管道读取或`wait`的系统调用会带来问题）。许多单处理器操作系统已经被转换为使用这种方法在多处理器上运行，有时被称为“大内核锁（big kernel lock）”，但是这种方法牺牲了并行性：一次只能有一个CPU运行在内核中。如果内核做一些繁重的计算，使用一组更细粒度的锁的集合会更有效率，这样内核就可以同时在多个处理器上执行。

作为粗粒度锁的一个例子，xv6的***kalloc.c***分配器有一个由单个锁保护的空闲列表。如果不同CPU上的多个进程试图同时分配页面，每个进程在获得锁之前将必须在`acquire`中自旋等待。自旋会降低性能，因为它只是无用的等待。如果对锁的争夺浪费了很大一部分CPU时间，也许可以通过改变分配器的设计来提高性能，使其拥有多个空闲列表，每个列表都有自己的锁，以允许真正的并行分配。

作为细粒度锁定的一个例子，xv6对每个文件都有一个单独的锁，这样操作不同文件的进程通常可以不需等待彼此的锁而继续进行。文件锁的粒度可以进一步细化，以允许进程同时写入同一个文件的不同区域。最终的锁粒度决策需要由性能测试和复杂性考量来驱动。

在后面的章节解释xv6的每个部分时，他们将提到xv6使用锁来处理并发的例子。作为预览，表6.3列出了xv6中的所有锁。

| **锁**                | **描述**                                               |
| --------------------- | ------------------------------------------------------ |
| `bcache.lock`         | 保护块缓冲区缓存项（block buffer cache entries）的分配 |
| `cons.lock`           | 串行化对控制台硬件的访问，避免混合输出                 |
| `ftable.lock`         | 串行化文件表中文件结构体的分配                         |
| `icache.lock`         | 保护索引结点缓存项（inode cache entries）的分配        |
| `vdisk_lock`          | 串行化对磁盘硬件和DMA描述符队列的访问                  |
| `kmem.lock`           | 串行化内存分配                                         |
| `log.lock`            | 串行化事务日志操作                                     |
| 管道的`pi->lock`      | 串行化每个管道的操作                                   |
| `pid_lock`            | 串行化next_pid的增量                                   |
| 进程的`p->lock`       | 串行化进程状态的改变                                   |
| `tickslock`           | 串行化时钟计数操作                                     |
| 索引结点的 `ip->lock` | 串行化索引结点及其内容的操作                           |
| 缓冲区的`b->lock`     | 串行化每个块缓冲区的操作                               |

 Figure 6.3: Locks in xv6

### 6.4 死锁和锁排序

如果在内核中执行的代码路径必须同时持有数个锁，那么所有代码路径以相同的顺序获取这些锁是很重要的。如果它们不这样做，就有死锁的风险。假设xv6中的两个代码路径需要锁A和B，但是代码路径1按照先A后B的顺序获取锁，另一个路径按照先B后A的顺序获取锁。假设线程T1执行代码路径1并获取锁A，线程T2执行代码路径2并获取锁B。接下来T1将尝试获取锁B，T2将尝试获取锁A。两个获取都将无限期阻塞，因为在这两种情况下，另一个线程都持有所需的锁，并且不会释放它，直到它的获取返回。为了避免这种死锁，所有代码路径必须以相同的顺序获取锁。全局锁获取顺序的需求意味着锁实际上是每个函数规范的一部分：调用者必须以一种使锁按照约定顺序被获取的方式调用函数。

由于`sleep`的工作方式（见第7章），Xv6有许多包含每个进程的锁（每个`struct proc`中的锁）在内的长度为2的锁顺序链。例如，`consoleintr` (***kernel/console.c:138***)是处理键入字符的中断例程。当换行符到达时，任何等待控制台输入的进程都应该被唤醒。为此，`consoleintr`在调用`wakeup`时持有`cons.lock`，`wakeup`获取等待进程的锁以唤醒它。因此，全局避免死锁的锁顺序包括必须在任何进程锁之前获取`cons.lock`的规则。文件系统代码包含xv6最长的锁链。例如，创建一个文件需要同时持有目录上的锁、新文件inode上的锁、磁盘块缓冲区上的锁、磁盘驱动程序的`vdisk_lock`和调用进程的`p->lock`。为了避免死锁，文件系统代码总是按照前一句中提到的顺序获取锁。

遵守全局死锁避免的顺序可能会出人意料地困难。有时锁顺序与逻辑程序结构相冲突，例如，也许代码模块M1调用模块M2，但是锁顺序要求在M1中的锁之前获取M2中的锁。有时锁的身份是事先不知道的，也许是因为必须持有一个锁才能发现下一个要获取的锁的身份。这种情况在文件系统中出现，因为它在路径名称中查找连续的组件，也在`wait`和`exit`代码中出现，因为它们在进程表中寻找子进程。最后，死锁的危险通常是对细粒度锁定方案的限制，因为更多的锁通常意味着更多的死锁可能性。避免死锁的需求通常是内核实现中的一个主要因素。

### 6.5 锁和中断处理函数

一些xv6自旋锁保护线程和中断处理程序共用的数据。例如，`clockintr`定时器中断处理程序在增加`ticks`(***kernel/trap.c:163***)的同时内核线程可能在`sys_sleep`(***kernel/sysproc.c:64***)中读取`ticks`。锁`tickslock`串行化这两个访问。

自旋锁和中断的交互引发了潜在的危险。假设`sys_sleep`持有`tickslock`，并且它的CPU被计时器中断中断。`clockintr`会尝试获取`tickslock`，意识到它被持有后等待释放。在这种情况下，`tickslock`永远不会被释放：只有`sys_sleep`可以释放它，但是`sys_sleep`直到`clockintr`返回前不能继续运行。所以CPU会死锁，任何需要锁的代码也会冻结。

为了避免这种情况，如果一个自旋锁被中断处理程序所使用，那么CPU必须保证在启用中断的情况下永远不能持有该锁。Xv6更保守：当CPU获取任何锁时，xv6总是禁用该CPU上的中断。中断仍然可能发生在其他CPU上，此时中断的`acquire`可以等待线程释放自旋锁；由于不在同一CPU上，不会造成死锁。

当CPU未持有自旋锁时，xv6重新启用中断；它必须做一些记录来处理嵌套的临界区域。`acquire`调用`push_off` (***kernel/spinlock.c:89***) 并且`release`调用`pop_off` (***kernel/spinlock.c:100***)来跟踪当前CPU上锁的嵌套级别。当计数达到零时，`pop_off`恢复最外层临界区域开始时存在的中断使能状态。`intr_off`和`intr_on`函数执行RISC-V指令分别用来禁用和启用中断。

严格的在设置`lk->locked` (***kernel/spinlock.c:28***)之前让`acquire`调用`push_off`是很重要的。如果两者颠倒，会存在一个既持有锁又启用了中断的短暂窗口期，不幸的话定时器中断会使系统死锁。同样，只有在释放锁之后，`release`才调用`pop_off`也是很重要的(***kernel/spinlock.c:66***)。

### 6.6 指令和内存访问排序

人们很自然地会想到程序是按照源代码语句出现的顺序执行的。然而，许多编译器和中央处理器为了获得更高的性能而不按顺序执行代码。如果一条指令需要许多周期才能完成，中央处理器可能会提前发出指令，这样它就可以与其他指令重叠，避免中央处理器停顿。例如，中央处理器可能会注意到在顺序指令序列A和B中彼此不存在依赖。CPU也许首先启动指令B，或者是因为它的输入先于A的输入准备就绪，或者是为了重叠执行A和B。编译器可以执行类似的重新排序，方法是在源代码中一条语句的指令发出之前，先发出另一条语句的指令。

编译器和CPU在重新排序时需要遵循一定规则，以确保它们不会改变正确编写的串行代码的结果。然而，规则确实允许重新排序后改变并发代码的结果，并且很容易导致多处理器上的不正确行为。CPU的排序规则称为内存模型（memory model）。

例如，在`push`的代码中，如果编译器或CPU将对应于第4行的存储指令移动到第6行`release`后的某个地方，那将是一场灾难：

```c
l = malloc(sizeof *l);
l->data = data;
acquire(&listlock);
l->next = list;
list = l;
release(&listlock);
```

如果发生这样的重新排序，将会有一个窗口期，另一个CPU可以获取锁并查看更新后的`list`，但却看到一个未初始化的`list->next`。

为了告诉硬件和编译器不要执行这样的重新排序，xv6在`acquire`(***kernel/spinlock.c:22***) 和`release`(***kernel/spinlock.c:47***)中都使用了`__sync_synchronize()`。`__sync_synchronize()`是一个内存障碍：它告诉编译器和CPU不要跨障碍重新排序`load`或`store`指令。因为xv6在访问共享数据时使用了锁，xv6的`acquire`和`release`中的障碍在几乎所有重要的情况下都会强制顺序执行。第9章讨论了一些例外。

### 6.7 睡眠锁

有时xv6需要长时间保持锁。例如，文件系统（第8章）在磁盘上读写文件内容时保持文件锁定，这些磁盘操作可能需要几十毫秒。如果另一个进程想要获取自旋锁，那么长时间保持自旋锁会导致获取进程在自旋时浪费很长时间的CPU。自旋锁的另一个缺点是，一个进程在持有自旋锁的同时不能让出（yield）CPU，然而我们希望持有锁的进程等待磁盘I/O的时候其他进程可以使用CPU。持有自旋锁时让步是非法的，因为如果第二个线程试图获取自旋锁，就可能导致死锁：因为`acquire`不会让出CPU，第二个线程的自旋可能会阻止第一个线程运行并释放锁。在持有锁时让步也违反了在持有自旋锁时中断必须关闭的要求。因此，我们想要一种锁，它在等待获取锁时让出CPU，并允许在持有锁时让步（以及中断）。

Xv6以睡眠锁（sleep-locks）的形式提供了这种锁。`acquiresleep` (***kernel/sleeplock.c:22***) 在等待时让步CPU，使用的技术将在第7章中解释。在更高层次上，睡眠锁有一个被自旋锁保护的锁定字段，`acquiresleep`对`sleep`的调用原子地让出CPU并释放自旋锁。结果是其他线程可以在`acquiresleep`等待时执行。

因为睡眠锁保持中断使能，所以它们不能用在中断处理程序中。因为`acquiresleep`可能会让出CPU，所以睡眠锁不能在自旋锁临界区域中使用（尽管自旋锁可以在睡眠锁临界区域中使用）。

因为等待会浪费CPU时间，所以自旋锁最适合短的临界区域；睡眠锁对于冗长的操作效果很好。



**lock的抽象结构**

![img](/home/sjh/Documents/Markdown_Note/MIT6.S801.assets/6_3.png)

保证在`acquire`和`release`之间的代码都是原子的（atomic），要么同时执行，要么一个都不执行。如果只有一把内核锁的话，那么kernel的大部分操作都将被串行化，极大程度减小了运行效率。

**什么时候需要锁**

![img](/home/sjh/Documents/Markdown_Note/MIT6.S801.assets/6_4.png)

当两个进程都在同时操作（读写）一处共享数据的时候，我们需要使用锁来保护这处的数据。

**加锁可以是自动的吗**？

这样会导致数据结构非常死板

![img](/home/sjh/Documents/Markdown_Note/MIT6.S801.assets/6_5.png)



锁的特性

- 锁防止丢失对变量的更新
- 锁保持操作是原子的
- 锁帮助保持不变性

![img](/home/sjh/Documents/Markdown_Note/MIT6.S801.assets/6_6.png)

**死锁**

死锁是一种在计算机系统中多个进程或线程因资源争夺而陷入永远等待的状态。常见的死锁情况可以归纳为以下两种：

**1.资源竞争导致的死锁**

- **场景**: 假设两个进程 `P1` 和 `P2` 分别持有资源 `R1` 和 `R2`，且它们都试图获取对方所持有的资源。

- 过程

  :

  1. `P1` 已经持有 `R1`，并请求 `R2`。
  2. `P2` 已经持有 `R2`，并请求 `R1`。
  3. 由于资源已被占用，`P1` 和 `P2` 互相等待对方释放资源，最终导致两者都无法继续执行，陷入死锁状态。

**2.循环等待导致的死锁**

- **场景**: 有多个进程组成一个循环等待链，每个进程都持有某个资源并等待下一个进程持有的资源。

- 过程

  :

  1. `P1` 持有资源 `R1`，并等待 `P2` 持有的 `R2`。
  2. `P2` 持有资源 `R2`，并等待 `P3` 持有的 `R3`。
  3. 最后，`P3` 持有资源 `R3`，并等待 `P1` 持有的 `R1`。
  4. 由于每个进程都在等待链中的下一个进程释放资源，导致所有进程都无法继续执行，形成死锁。

![img](/home/sjh/Documents/Markdown_Note/MIT6.S801.assets/6_7.png)



解决办法是让锁的获得顺序符合某种全局的锁顺序。

**locks vs performance**

![img](/home/sjh/Documents/Markdown_Note/MIT6.S801.assets/6_8.png)

提升performance的方法就是将数据结构进行拆分

锁使用的基本原则：在任何时间持有相同锁的进程不能超过一个。



减少软件来实现原子性，而是使用硬操作来实现，利用硬件提供的`test and set support`来实现锁，在RISC-V中硬件提供了`amoswap addr r1, r2`支持，采用原子的步骤交换两个地址之间的值，C语言中实现了这种支持，这里是`__sync_lock_test_and_set`。

![img](/home/sjh/Documents/Markdown_Note/MIT6.S801.assets/6_10.png)

![img](/home/sjh/Documents/Markdown_Note/MIT6.S801.assets/6_9.png)



为什么不能直接写入，因为C语言的一条赋值或者计算语句不是原子的，一条C语言语句可能对应多条汇编语句，例如：

`a++`不是原子的，对应

```c
mov eax, dword ptr [a] 	# (1)
inc eax					# (2)
mov dword ptr [a], eax	# (3)
```

在这种情况下，我们的单条C语句我们认为是原子的，其实可能引起多个CPU正在获取或者释放锁，可能会导致死锁。

> locks good for cocurrences
>
> locks can be bad for performance
>
> locks complicate the programming
>
> don't share data structure if you don't have to
>
> start with coarse-grained, then turn to fine-grained



什么是线程Thread？

线程是一个单一的串行执行（Thread is one serial excecution）

- xv6中的kernel threads会共享内存
- xv6中的用户进程只有一个线程，不会共享内存
- linux user中的用户进程有多个线程，会在彼此之间共享内存。

![img](/home/sjh/Documents/Markdown_Note/MIT6.S801.assets/6_11.png)

Thread chanllenges:

- Switching, interleaue
  - scheduling
- want to save and restore
- compute bound

线程的状态有:

- runing已运行
- runable可运行，这时我们需要保存program counter和register
- sleeping睡眠
- unused未使用
- zombie待回收

pre-emptiue sheduling（抢占式调度）

**xv6切换线程的过程**（Context switch）：

比如当我们需要从一个编译器线程`cc`切换到`ls`线程，我们先通过`trampoline`进入kernel然后获得`trapframe`和`kernel stack`，然后我们通过`scheduler`切换到`ls`线程所对应的内核线程，然后从kernel恢复到user。

![](/home/sjh/Documents/Markdown_Note/MIT6.S801.assets/6_12.png)

在切换线程的时候，使用`p->context`来存储需要保存或者恢复的数据

在xv6中每个进程都有两个线程，一个是用户线程，一个是内核线程，要么在用户空间执行用户程序，要么在内核空间执行系统调用或中断，两者不能同时执行，所以也可以理解为单线程。

`swtch.S`完成了内核线程中`context old`的保存和`context new`的加载，其实就是在保存和加载一些寄存器中的内容，一个thread还包含许多的变量或函数，这些东西都存放在内存中他们不是易改变，我们没有写任何代码来改变它们，只要指向这些内容的寄存器是正确的，那么就能从内存中恢复这些内容，这些不是易失去的，相反寄存器中的内容才是`volatile`的。